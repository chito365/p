---
id: 92
title: 'An Overview of Human Error &#8211; Com 410 Cs Notes'
date: 2015-11-01T15:53:00+00:00
author: chito
layout: post
guid: http://www.afriqueunique.org/2015/11/01/11934050/
permalink: /2015/11/01/11934050/
swp_pinterest_image_url:
  - ""
swp_cache_timestamp:
  - "419230"
post_views_count:
  - "157"
bs_social_share_facebook:
  - "0"
bs_social_share_twitter:
  - "0"
bs_social_share_reddit:
  - "0"
bs_social_share_google_plus:
  - "0"
bs_social_share_linkedin:
  - "0"
bs_social_share_interval:
  - "1570906651"
categories:
  - LEARNING
---
<span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">An Overview of Human Error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">Drawn from J. Reason, <span style="font-family:'Comic Sans MS Italic';"><em>Human Error</em><span style="font-family:'Comic Sans MS';">, Cambridge, 1990<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 2<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Outline<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">A theory of human error<br /><span style="font-family:'Comic Sans MS';">• <span style="font-family:'Comic Sans MS Bold';">Human error and accident theory<br /><span style="font-family:'Comic Sans MS';">• <span style="font-family:'Comic Sans MS Bold';">Addressing human error<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 3<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Outline<br /><span style="font-family:'Comic Sans MS';color:rgb(145,145,145);">• <span style="font-family:'Comic Sans MS Bold';">Human error and computer system failures<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">A theory of human error<br /><span style="font-family:'Comic Sans MS';color:rgb(145,145,145);">• <span style="font-family:'Comic Sans MS Bold';">Human error and accident theory<br /><span style="font-family:'Comic Sans MS';">• <span style="font-family:'Comic Sans MS Bold';">Addressing human error<br /><span style="font-family:'Arial Bold';">Slide 4<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">A theory of human error<br /><span style="font-family:'Comic Sans MS Italic';color:rgb(0,0,120);"><em>(distilled from J. Reason, Human Error, 1990)</em><br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Preliminaries: the three stages of cognitive<br />processing for tasks<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">1) planning<br /><span style="color:rgb(0,0,69);">» a goal is identified and a sequence of actions is selected<br />to reach the goal<br /><span style="color:rgb(0,0,120);">2) storage<br /><span style="color:rgb(0,0,69);">» the selected plan is stored in memory until it is<br />appropriate to carry it out<br /><span style="color:rgb(0,0,120);">3) execution<br /><span style="color:rgb(0,0,69);">» the plan is implemented by the process of carrying out<br />the actions specified by the plan<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 5<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">A theory of human error (2)<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Each cognitive stage has an associated form<br />of error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">slips: <span style="font-family:'Comic Sans MS';">execution stage<br /><span style="color:rgb(0,0,69);">» incorrect execution of a planned action<br />» example: miskeyed command<br /><span style="color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">lapses: <span style="font-family:'Comic Sans MS';">storage stage<br /><span style="color:rgb(0,0,69);">» incorrect omission of a stored, planned action<br />» examples: skipping a step on a checklist, forgetting to<br />restore normal valve settings after maintenance<br /><span style="color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">mistakes: <span style="font-family:'Comic Sans MS';">planning stage<br /><span style="color:rgb(0,0,69);">» the plan is not suitable for achieving the desired goal<br />» example: TMI operators prematurely disabling HPI<br />pumps<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 6<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Origins of error: the GEMS model<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">GEMS: Generic Error-Modeling System<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– an attempt to understand the origins of human error<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">GEMS identifies three <span style="font-family:'Comic Sans MS Bold Italic';"><em>levels</em> <span style="font-family:'Comic Sans MS Bold';">of cognitive task<br />processing<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">skill-based: <span style="font-family:'Comic Sans MS';">familiar, automatic procedural tasks<br /><span style="color:rgb(0,0,69);">» usually low-level, like knowing to type “ls” to list files<br /><span style="color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">rule-based: <span style="font-family:'Comic Sans MS';">tasks approached by pattern-matching<br />from a set of internal problem-solving rules<br /><span style="color:rgb(0,0,69);">» “observed symptoms X mean system is in state Y”<br />» “if system state is Y, I should probably do Z to fix it”<br /><span style="color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">knowledge-based: <span style="font-family:'Comic Sans MS';">tasks approached by reasoning<br />from first principles<br /><span style="color:rgb(0,0,69);">» when rules and experience don’t apply<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 7<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">GEMS and errors<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Errors can occur at each level<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">skill-based: <span style="font-family:'Comic Sans MS';">slips and lapses<br /><span style="color:rgb(0,0,69);">» usually errors of inattention or misplaced attention<br /><span style="color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">rule-based: <span style="font-family:'Comic Sans MS';">mistakes<br /><span style="color:rgb(0,0,69);">» usually a result of picking an inappropriate rule<br />» caused by misconstrued view of state, over-zealous<br />pattern matching, frequency gambling, deficient rules<br /><span style="color:rgb(0,0,120);">– <span style="font-family:'Comic Sans MS Bold';">knowledge-based: <span style="font-family:'Comic Sans MS';">mistakes<br /><span style="color:rgb(0,0,69);">» due to incomplete/inaccurate understanding of system,<br />confirmation bias, overconfidence, cognitive strain, &#8230;<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Errors can result from operating at wrong level<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– humans are reluctant to move from RB to KB level even<br />if rules aren’t working<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 8<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Error frequencies<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">In raw frequencies, SB >> RB > KB<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– 61% of errors are at skill-based level<br />– 27% of errors are at rule-based level<br />– 11% of errors are at knowledge-based level<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">But if we look at <span style="font-family:'Comic Sans MS Bold Italic';"><em>opportunities</em> <span style="font-family:'Comic Sans MS Bold';">for error, the<br />order reverses<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– humans perform vastly more SB tasks than RB, and<br />vastly more RB than KB<br /><span style="color:rgb(0,0,69);">» so a given KB task is more likely to result in error than<br />a given RB or SB task<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 9<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Error detection and correction<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Basic detection mechanism is self-monitoring<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– periodic attentional checks, measurement of progress<br />toward goal, discovery of surprise inconsistencies, &#8230;<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Effectiveness of self-detection of errors<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– SB errors: 75-95% detected, avg 86%<br /><span style="color:rgb(0,0,69);">» but some lapse-type errors were resistant to detection<br /><span style="color:rgb(0,0,120);">– RB errors: 50-90% detected, avg 73%<br />– KB errors: 50-80% detected, avg 70%<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Including correction tells a different story:<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– SB: <span style="font-size:16pt">70% of all errors detected and corrected<br />– RB:</span> 50% detected and corrected<br />– KB: ~25% detected and corrected<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 10<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Outline<br /><span style="font-family:'Comic Sans MS';color:rgb(145,145,145);">• <span style="font-family:'Comic Sans MS Bold';">Human error and computer system failures<br /><span style="font-family:'Comic Sans MS';">• <span style="font-family:'Comic Sans MS Bold';">A theory of human error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Human error and accident theory<br /><span style="font-family:'Comic Sans MS';color:rgb(145,145,145);">• <span style="font-family:'Comic Sans MS Bold';">Addressing human error<br /><span style="font-family:'Arial Bold';">Slide 11<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Human error and accident theory<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Major systems accidents (“normal accidents”)<br />start with an accumulation of latent errors<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– most of those latent errors are human errors<br /><span style="color:rgb(0,0,69);">» latent slips/lapses, particularly in maintenance<br /><span style="color:rgb(0,0,0);">• example: misconfigured valves in TMI<br /><span style="color:rgb(0,0,69);">» latent mistakes in system design, organization, and<br />planning, particularly of emergency procedures<br /><span style="color:rgb(0,0,0);">• example: flowcharts that omit unforeseen paths<br /><span style="color:rgb(0,0,120);">– invisible latent errors change system reality without<br />altering operator’s models<br /><span style="color:rgb(0,0,69);">» seemingly-correct actions can then trigger accidents<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 12<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Accident theory (2)<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Accidents are exacerbated by human errors<br />made during operator response<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– RB errors made due to lack of experience with system<br />in failure states<br /><span style="color:rgb(0,0,69);">» training is rarely sufficient to develop a rule base that<br />captures system response outside of normal bounds<br /><span style="color:rgb(0,0,120);">– KB reasoning is hindered by system complexity and<br />cognitive strain<br /><span style="color:rgb(0,0,69);">» system complexity prohibits mental modeling<br />» stress of an emergency encourages RB approaches and<br />diminishes KB effectiveness<br /><span style="color:rgb(0,0,120);">– system visibility limited by automation and “defense in<br />depth”<br /><span style="color:rgb(0,0,69);">» results in improper rule choices and KB reasoning<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 13<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Outline<br /><span style="font-family:'Comic Sans MS';color:rgb(145,145,145);">• <span style="font-family:'Comic Sans MS Bold';">Human error and computer system failures<br /><span style="font-family:'Comic Sans MS';">• <span style="font-family:'Comic Sans MS Bold';">A theory of human error<br /><span style="font-family:'Comic Sans MS';">• <span style="font-family:'Comic Sans MS Bold';">Human error and accident theory<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Addressing human error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– general guidelines<br />– the ROC approach: system-level undo<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 14<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Addressing human error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Challenges<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– humans are inherently fallible and errors are inevitable<br />– hard-to-detect latent errors can be more troublesome<br />than front-line errors<br />– human psychology must not be ignored<br /><span style="color:rgb(0,0,69);">» especially the SB/RB/KB distinction and human behavior<br />at each level<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">General approach: error-tolerance rather than<br />error-avoidance<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">“It is now widely held among human reliability specialists<br />that the most productive strategy for dealing with active<br />errors is to focus upon controlling their consequences<br />rather than upon striving for their elimination.”<br />(Reason, p. 246)<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 15<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">The Automation Irony<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Automation is not the cure for human error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– automation addresses the easy SB/RB tasks, leaving<br />the complex KB tasks for the human<br /><span style="color:rgb(0,0,69);">» humans are ill-suited to KB tasks, especially under<br />stress<br /><span style="color:rgb(0,0,120);">– automation hinders understanding and mental modeling<br /><span style="color:rgb(0,0,69);">» decreases system visibility and increases complexity<br />» operators don’t get hands-on control experience<br />» rule-set for RB tasks and models for KB tasks are weak<br /><span style="color:rgb(0,0,120);">– automation shifts the error source from operator<br />errors to design errors<br /><span style="color:rgb(0,0,69);">» harder to detect/tolerate/fix design errors<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 16<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Building robustness to human error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Discover and correct latent errors<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– must overcome human nature to wait until emergency<br />to respond<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Increase system visibility<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– don’t hide complexity behind automated mechanisms<br /><span style="color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Take errors into account in operator training<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– include error scenarios<br />– promote exploratory trial & error approaches<br />– emphasize positive side of errors: learning from<br />mistakes<br /><span style="font-family:'Arial Bold';color:rgb(145,145,145);">Slide 17<br /><span style="font-family:'Comic Sans MS Bold';color:rgb(220,47,0);">Building robustness to human error<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,180);">• <span style="font-family:'Comic Sans MS Bold';">Reduce opportunities for error (Don Norman):<br /><span style="font-family:'Comic Sans MS';color:rgb(0,0,120);">– get good conceptual model to user by consistent design<br />– design tasks to match human limits: working memory,<br />problem solving abilities<br />– make visible what the options are, and what are the<br />consequences of actions<br />– exploit natural mappings: between intentions and possible<br />actions, actual state and what is perceived, …<br />– use constraints to guide user to next action/decision<br /><span style="color:rgb(0,174,0);">– design for errors. Assume their occurrence. Plan for error<br /></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>